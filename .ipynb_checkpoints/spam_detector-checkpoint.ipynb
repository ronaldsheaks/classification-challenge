{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the Data\n",
    "\n",
    "The data is located at [https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv](https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv)\n",
    "\n",
    "Dataset Source: [UCI Machine Learning Library](https://archive.ics.uci.edu/dataset/94/spambase)\n",
    "\n",
    "Import the data using Pandas. Display the resulting DataFrame to confirm the import was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...         0.00        0.000   \n",
       "1             0.00            0.94  ...         0.00        0.132   \n",
       "2             0.64            0.25  ...         0.01        0.143   \n",
       "3             0.31            0.63  ...         0.00        0.137   \n",
       "4             0.31            0.63  ...         0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  spam  \n",
       "0                       278     1  \n",
       "1                      1028     1  \n",
       "2                      2259     1  \n",
       "3                       191     1  \n",
       "4                       191     1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "data = pd.read_csv(\"https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Model Performance\n",
    "\n",
    "You will be creating and comparing two models on this data: a Logistic Regression, and a Random Forests Classifier. Before you create, fit, and score the models, make a prediction as to which model you think will perform better. You do not need to be correct! \n",
    "\n",
    "Write down your prediction in the designated cells in your Jupyter Notebook, and provide justification for your educated guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Replace the text in this markdown cell with your predictions, and be sure to provide justification for your guess.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n",
       "0             0.00            0.00  ...                   0.0         0.00   \n",
       "1             0.00            0.94  ...                   0.0         0.00   \n",
       "2             0.64            0.25  ...                   0.0         0.01   \n",
       "3             0.31            0.63  ...                   0.0         0.00   \n",
       "4             0.31            0.63  ...                   0.0         0.00   \n",
       "\n",
       "   char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0        0.000          0.0        0.778        0.000        0.000   \n",
       "1        0.132          0.0        0.372        0.180        0.048   \n",
       "2        0.143          0.0        0.276        0.184        0.010   \n",
       "3        0.137          0.0        0.137        0.000        0.000   \n",
       "4        0.135          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  \n",
       "0                       278  \n",
       "1                      1028  \n",
       "2                      2259  \n",
       "3                       191  \n",
       "4                       191  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the labels set `y` and features DataFrame `X`\n",
    "# Separate the target (labels) and the features\n",
    "y = data['spam']  # Labels set (1 for spam, 0 for not spam)\n",
    "X = data.drop(columns=['spam'])  # Features DataFrame (all columns except 'spam')\n",
    "\n",
    "# Display the first few rows to ensure everything looks good\n",
    "y.head()\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam\n",
       "0    2788\n",
       "1    1813\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the balance of the labels variable (`y`) by using the `value_counts` function.\n",
    "# Check the balance of the labels variable `y`\n",
    "y.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3450, 57), (1151, 57), (3450,), (1151,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "# Display the shape of the training and testing sets to ensure the split is correct\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `StandardScaler` to scale the features data. Remember that only `X_train` and `X_test` DataFrames should be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.58119247e-01, -1.67442483e-01, -5.60719811e-01,\n",
       "        -4.46473474e-02, -4.59892856e-01, -3.49536339e-01,\n",
       "        -2.89221127e-01, -2.57390456e-01, -3.25494386e-01,\n",
       "        -3.68236379e-01, -2.96782976e-01, -2.00936256e-01,\n",
       "         8.96106323e-01, -1.78141773e-01, -1.95485765e-01,\n",
       "        -2.90828602e-01, -3.14328299e-01, -3.59031196e-01,\n",
       "        -1.10265583e-01, -1.67833588e-01, -6.74105571e-01,\n",
       "        -1.25609948e-01, -3.00556311e-01, -2.11588600e-01,\n",
       "        -3.19534496e-01, -2.96827421e-01, -2.28806843e-01,\n",
       "        -2.20881186e-01, -1.63910377e-01, -2.14489708e-01,\n",
       "        -1.66944738e-01, -1.39766111e-01, -1.69939825e-01,\n",
       "        -1.41266615e-01, -1.81039040e-01,  6.66171634e-01,\n",
       "        -3.21758938e-01, -6.17380835e-02, -1.78696230e-01,\n",
       "        -1.81332333e-01,  9.59601986e-01, -1.72921915e-01,\n",
       "        -2.04370833e-01, -1.38553647e-01,  7.94038887e-01,\n",
       "         2.35039055e-01, -7.26358934e-02, -1.05121873e-01,\n",
       "        -1.57100242e-01, -2.80440232e-02, -1.49121568e-01,\n",
       "        -3.15969568e-01, -3.09937873e-01, -1.04775676e-01,\n",
       "        -1.39746777e-01, -2.30233280e-01, -3.75484239e-01],\n",
       "       [-3.58119247e-01, -1.67442483e-01, -5.60719811e-01,\n",
       "        -4.46473474e-02, -4.59892856e-01, -3.49536339e-01,\n",
       "        -2.89221127e-01, -2.57390456e-01, -3.25494386e-01,\n",
       "        -3.68236379e-01, -2.96782976e-01, -6.24349261e-01,\n",
       "        -3.12493942e-01, -1.78141773e-01, -1.95485765e-01,\n",
       "        -2.90828602e-01, -3.14328299e-01, -3.59031196e-01,\n",
       "         6.81767094e+00, -1.67833588e-01, -6.74105571e-01,\n",
       "        -1.25609948e-01, -3.00556311e-01, -2.11588600e-01,\n",
       "        -3.19534496e-01, -2.96827421e-01, -2.28806843e-01,\n",
       "        -2.20881186e-01, -1.63910377e-01, -2.14489708e-01,\n",
       "        -1.66944738e-01, -1.39766111e-01, -1.69939825e-01,\n",
       "        -1.41266615e-01, -1.81039040e-01, -2.32965664e-01,\n",
       "        -3.21758938e-01, -6.17380835e-02, -1.78696230e-01,\n",
       "        -1.81332333e-01, -1.19062980e-01, -1.72921915e-01,\n",
       "        -2.04370833e-01, -1.38553647e-01, -3.04359058e-01,\n",
       "        -2.09406408e-01, -7.26358934e-02, -1.05121873e-01,\n",
       "        -1.57100242e-01, -4.77717487e-01, -1.49121568e-01,\n",
       "        -3.15969568e-01, -3.09937873e-01, -1.04775676e-01,\n",
       "        -1.36405716e-01, -2.30233280e-01, -4.64667043e-01],\n",
       "       [ 2.13176655e-01, -1.67442483e-01, -2.23912354e-01,\n",
       "        -4.46473474e-02, -4.59892856e-01, -3.49536339e-01,\n",
       "        -2.89221127e-01, -2.57390456e-01,  2.42524662e+00,\n",
       "        -3.68236379e-01, -2.96782976e-01, -3.26815798e-01,\n",
       "        -3.12493942e-01, -1.78141773e-01,  1.25344771e-01,\n",
       "        -2.90828602e-01, -3.14328299e-01, -3.59031196e-01,\n",
       "        -7.41588336e-01, -1.67833588e-01, -5.36186511e-01,\n",
       "        -1.25609948e-01, -3.00556311e-01, -2.11588600e-01,\n",
       "         4.32683528e-02,  4.86417866e-01, -2.05255017e-01,\n",
       "        -2.20881186e-01, -1.63910377e-01, -2.14489708e-01,\n",
       "        -1.66944738e-01, -1.39766111e-01,  2.93828538e-01,\n",
       "        -1.41266615e-01, -1.81039040e-01, -3.85575994e-02,\n",
       "         7.18937518e-01, -6.17380835e-02, -1.78696230e-01,\n",
       "        -1.81332333e-01, -1.19062980e-01, -1.72921915e-01,\n",
       "        -2.04370833e-01, -1.38553647e-01, -3.04359058e-01,\n",
       "        -2.09406408e-01, -7.26358934e-02, -1.05121873e-01,\n",
       "         7.97084576e-01,  9.89629858e-02,  5.36032859e-01,\n",
       "        -3.15969568e-01, -2.13010221e-01, -1.04775676e-01,\n",
       "        -1.18606209e-02,  1.30085967e-01,  1.25168127e+00],\n",
       "       [-3.58119247e-01, -1.67442483e-01, -5.60719811e-01,\n",
       "        -4.46473474e-02, -4.59892856e-01, -3.49536339e-01,\n",
       "        -2.89221127e-01, -2.57390456e-01, -3.25494386e-01,\n",
       "        -3.68236379e-01, -2.96782976e-01,  1.06930276e+00,\n",
       "        -3.12493942e-01, -1.78141773e-01, -1.95485765e-01,\n",
       "        -2.90828602e-01, -3.14328299e-01, -3.59031196e-01,\n",
       "        -9.35415497e-01, -1.67833588e-01, -6.74105571e-01,\n",
       "        -1.25609948e-01, -3.00556311e-01, -2.11588600e-01,\n",
       "         9.79533768e-01,  5.19512737e-01, -2.28806843e-01,\n",
       "        -2.20881186e-01, -1.63910377e-01,  1.41908991e+00,\n",
       "        -1.66944738e-01, -1.39766111e-01, -1.69939825e-01,\n",
       "        -1.41266615e-01, -1.81039040e-01, -2.32965664e-01,\n",
       "         3.17876550e+00, -6.17380835e-02,  2.99020923e+00,\n",
       "        -1.81332333e-01, -1.19062980e-01, -1.72921915e-01,\n",
       "        -2.04370833e-01, -1.38553647e-01, -3.04359058e-01,\n",
       "        -2.09406408e-01, -7.26358934e-02, -1.05121873e-01,\n",
       "        -1.57100242e-01, -4.77717487e-01, -1.49121568e-01,\n",
       "        -3.15969568e-01, -3.09937873e-01, -1.04775676e-01,\n",
       "        -2.94515086e-02, -2.66322921e-03, -2.34137907e-01],\n",
       "       [-3.58119247e-01, -1.67442483e-01, -5.60719811e-01,\n",
       "        -4.46473474e-02,  2.76436159e+00, -3.49536339e-01,\n",
       "        -2.89221127e-01, -2.57390456e-01, -3.25494386e-01,\n",
       "        -3.68236379e-01, -2.96782976e-01,  1.85891080e+00,\n",
       "        -3.12493942e-01, -1.78141773e-01, -1.95485765e-01,\n",
       "         2.21396096e+00, -3.14328299e-01,  3.83038424e+00,\n",
       "         2.67530762e+00, -1.67833588e-01,  1.08639068e+00,\n",
       "        -1.25609948e-01, -3.00556311e-01, -2.11588600e-01,\n",
       "        -3.19534496e-01, -2.96827421e-01, -2.28806843e-01,\n",
       "        -2.20881186e-01, -1.63910377e-01, -2.14489708e-01,\n",
       "        -1.66944738e-01, -1.39766111e-01, -1.69939825e-01,\n",
       "        -1.41266615e-01, -1.81039040e-01, -2.32965664e-01,\n",
       "        -3.21758938e-01, -6.17380835e-02, -1.78696230e-01,\n",
       "        -1.81332333e-01, -1.19062980e-01, -1.72921915e-01,\n",
       "        -2.04370833e-01, -1.38553647e-01, -3.04359058e-01,\n",
       "        -2.09406408e-01, -7.26358934e-02, -1.05121873e-01,\n",
       "        -1.57100242e-01, -4.77717487e-01, -1.49121568e-01,\n",
       "        -3.15969568e-01, -3.09937873e-01, -1.04775676e-01,\n",
       "        -1.45986108e-01, -2.30233280e-01, -4.56253571e-01]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the Standard Scaler with the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Scale the training and testing features DataFrames\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Display the first few rows of the scaled training data to ensure it's working correctly\n",
    "X_train_scaled[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Standard Scaler with the training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# You’ve already done the transform:\n",
    "# X_train_scaled = scaler.transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the training data\n",
    "#Already did it, in previous steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit a Logistic Regression Model\n",
    "\n",
    "Create a Logistic Regression model, fit it to the training data, make predictions with the testing data, and print the model's accuracy score. You may choose any starting settings you like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy: 0.9287576020851434\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual  Predicted\n",
       "1351       1          0\n",
       "1687       1          0\n",
       "1297       1          1\n",
       "2101       0          0\n",
       "3920       0          0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Logistic Regression model and print the model score\n",
    "\n",
    "# Create the Logistic Regression model\n",
    "logistic_regression_model = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit the model with the scaled training data\n",
    "logistic_regression_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using the logistic regression model\n",
    "y_pred_logistic = logistic_regression_model.predict(X_test_scaled)\n",
    "\n",
    "# Save the predictions to a variable\n",
    "testing_predictions = y_pred_logistic\n",
    "\n",
    "# Calculate the accuracy score by evaluating y_test vs. testing_predictions\n",
    "accuracy_logistic = accuracy_score(y_test, testing_predictions)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Logistic Regression Model Accuracy:\", accuracy_logistic)\n",
    "\n",
    "# Review the first few predictions alongside the actual labels\n",
    "predictions_comparison = pd.DataFrame({\"Actual\": y_test, \"Predicted\": testing_predictions})\n",
    "predictions_comparison.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Accuracy: 0.9669852302345786\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual  Predicted\n",
       "1351       1          1\n",
       "1687       1          1\n",
       "1297       1          1\n",
       "2101       0          0\n",
       "3920       0          0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make and save testing predictions with the saved logistic regression model using the test data\n",
    "\n",
    "# Review the predictions\n",
    "\n",
    "# Make predictions on the test set using the logistic regression model\n",
    "\n",
    "# Save the predictions to a variable\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Step 1: Create the Random Forest Classifier model\n",
    "random_forest_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Step 2: Fit the model with the scaled training data\n",
    "random_forest_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 3: Make predictions on the test set using the random forest model\n",
    "y_pred_rf = random_forest_model.predict(X_test_scaled)\n",
    "\n",
    "# Step 4: Save the predictions to a variable\n",
    "testing_predictions_rf = y_pred_rf\n",
    "\n",
    "# Step 5: Calculate the accuracy score by evaluating y_test vs. testing_predictions_rf\n",
    "accuracy_rf = accuracy_score(y_test, testing_predictions_rf)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Random Forest Model Accuracy:\", accuracy_rf)\n",
    "\n",
    "# Step 6: Review the first few predictions alongside the actual labels\n",
    "predictions_comparison_rf = pd.DataFrame({\"Actual\": y_test, \"Predicted\": testing_predictions_rf})\n",
    "predictions_comparison_rf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy score by evaluating `y_test` vs. `testing_predictions`.\n",
    "# Did this last step, the accuracy score is : Logistic Regression Model Accuracy: 0.9287576020851434\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit a Random Forest Classifier Model\n",
    "\n",
    "Create a Random Forest Classifier model, fit it to the training data, make predictions with the testing data, and print the model's accuracy score. You may choose any starting settings you like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Accuracy: 0.9669852302345786\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create the Random Forest Classifier model\n",
    "random_forest_model = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Fit the model with the scaled training data\n",
    "random_forest_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set using the random forest model\n",
    "y_pred_rf = random_forest_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the accuracy score by evaluating y_test vs. y_pred_rf\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Random Forest Model Accuracy:\", accuracy_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Actual  Predicted\n",
       "1351       1          0\n",
       "1687       1          0\n",
       "1297       1          1\n",
       "2101       0          0\n",
       "3920       0          0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make and save testing predictions with the saved logistic regression model using the test data\n",
    "\n",
    "# Make predictions on the test set using the logistic regression model\n",
    "y_pred_logistic = logistic_regression_model.predict(X_test_scaled)\n",
    "\n",
    "# Save the predictions to a variable\n",
    "testing_predictions_logistic = y_pred_logistic\n",
    "\n",
    "# Review the predictions\n",
    "# Review the first few predictions alongside the actual labels\n",
    "predictions_comparison_logistic = pd.DataFrame({\"Actual\": y_test, \"Predicted\": testing_predictions_logistic})\n",
    "predictions_comparison_logistic.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Accuracy: 0.9287576020851434\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score by evaluating `y_test` vs. `testing_predictions`.\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate the accuracy score by evaluating y_test vs. testing_predictions_logistic\n",
    "accuracy_logistic = accuracy_score(y_test, testing_predictions_logistic)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Logistic Regression Model Accuracy:\", accuracy_logistic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Models\n",
    "\n",
    "Which model performed better? How does that compare to your prediction? Write down your results and thoughts in the following markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Replace the text in this markdown cell with your answers to these questions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model Evaluation\n",
    "\n",
    "#1. Logistic Regression Model:\n",
    "\n",
    "#Accuracy: 92.88%\n",
    "#Observations: The logistic regression model performed well, correctly classifying the majority of the spam and non-spam emails. However, it did struggle with some misclassifications, particularly with the spam emails, where it falsely labeled some spam emails as legitimate.\n",
    "#2. Random Forest Model:\n",
    "\n",
    "#Accuracy: 96.70%\n",
    "#Observations: The random forest model outperformed the logistic regression model, achieving a higher accuracy score. It was better at correctly classifying both spam and non-spam emails, making it the more reliable model for this dataset.\n",
    "\n",
    "#Conclusion:\n",
    "#The Random Forest model performed better in terms of accuracy, correctly classifying a higher percentage of emails compared to the logistic regression model. This aligns with what we might expect, as Random Forest is generally more powerful for classification tasks, particularly when dealing with complex datasets. My initial prediction might have leaned towards logistic regression due to its simplicity and speed, but the Random Forest model’s ability to handle variability and capture more intricate patterns in the data proved to be more effective for this spam classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
